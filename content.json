{"meta":{"title":"Lin's","subtitle":"Stay Hungry, Stay Foolish","description":null,"author":"Kevin","url":"http://fwiskevin.github.io","root":"/"},"pages":[{"title":"tags","date":"2021-11-01T01:12:37.000Z","updated":"2021-11-01T01:13:12.951Z","comments":true,"path":"tags/index.html","permalink":"http://fwiskevin.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-11-01T01:14:02.000Z","updated":"2021-11-01T01:15:38.347Z","comments":true,"path":"categories/index.html","permalink":"http://fwiskevin.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Python 面向对象部分内容","slug":"PythonLearningNotes","date":"2021-08-07T23:54:29.000Z","updated":"2021-12-21T11:21:17.278Z","comments":true,"path":"2021/08/08/PythonLearningNotes/","link":"","permalink":"http://fwiskevin.github.io/2021/08/08/PythonLearningNotes/","excerpt":"廖雪峰老师Python新手教程的学习摘录笔记","text":"廖雪峰老师Python新手教程的学习摘录笔记 Python的学习笔记主要参考廖雪峰老师的Python新手教程，一些摘抄和自己的理解。同时也有参考其他的资料，部分参考出处忘记收录了。（下次一定 ⊙﹏⊙∥） 附上教程链接：廖雪峰Python教程 Q&amp;A class 中为什么总是有__init__方法，干什么用的？__init__方法用来绑定类中必须拥有的属性，在创建实例的时候，若有__init__方法就不能传入空的参数，但是 self不用传，Python解释器会自己把实例变量传进去。 在创建类时，方法中的 self参数到底是个啥？在类中的函数（或者说方法）第一个参数”永远“是 self，代表创建的实例本身，用于在内部相互调用。 e.g. c = self.add() + self.str2int() class Student(object)中 object表示什么？表示该类是从哪个类继承下来的。若没有继承的类，默认为object，因为所有的类都是继承自object类。 变量名中前双下划线和前后双下划线的意义？在 Python中，变量名类似__xxx__的为特殊变量，其可以直接访问，非 private变量。类似__xxx的为私有变量，外部不能访问。而类似_xxx的是按照约定俗成的规定，虽然可以从外部访问，但是视为私有变量。 在 class 中的 __init__ 方法里总是可以看到super().__init___()，这是什么？ 使用@property装饰器1234567891011class Student(object): @property #装饰器@property使getter方法转化为属性 def score(self): return self._score @score.setter #@property本身又创建了另一个装饰器@score.setter，负责把setter方法变成属性赋值 def score(self, value): if not isinstance(value, int): raise ValueError(&#x27;score must be an integer&#x27;) if value &lt; 0 or value &gt; 100 : raise ValueError(&#x27;score must between 0~100&#x27;) self._score = value 多重继承通过多重继承，一个子类就可以同时获得多个父类的所有功能。 12345678910111213141516171819202122232425class Animal(object): pass#大类class Mammal(Animal): passclass Bird(Animal): pass#各类动物class Dog(Mammal): passclass Bat(Mammal): passclass Parrot(Bird): pass#定义新类class Runnerable(object): def run(self): print(&#x27;Running&#x27;)class Flyable(object): def fly(&#x27;Flying&#x27;)#多重继承class Dog(Mammal, Runnable): passclass Bat(Mammal,Flyable): pass MixIn设计为了更好地看出继承关系，我们把 Runnable和 Flyable改为 RunnableMixIn和 FlyableMixIn。类似的，你还可以定义出肉食动物 CarnivorousMixIn和植食动物 HerbivoresMixIn，让某个动物同时拥有好几个 MixIn： 12class Dog(Mammal, RunnableMixIn, CarnivorousMixIn): pass MixIn 的目的就是给一个类增加多个功能，这样，在设计类的时候，我们优先考虑通过多重继承来组合多个 MixIn 的功能，而不是设计多层次的复杂的继承关系。 定制类__str__ &amp; __repr__123456789class Student(object): def __init__(self, name): self.name = name#__str__()方法返回用户看到的字符串 def __str__(self): return &#x27;Student object (name= %s)&#x27; % self.name#直接显示变量需要调用__repr__()方法，其为程序员调试使用 __repr__ = __str__ __iter__12345678910111213141516&#x27;&#x27;&#x27;如果一个类想被用于 for ... in 循环，类似 list 或 tuple 那样，就必须实现一个__iter__()方法，该方法返回一个迭代对象，然后，Python 的 for循环就会不断调用该迭代对象的__next__()方法拿到循环的下一个值，直到遇到 StopIteration 错误时退出循环。&#x27;&#x27;&#x27;class Fib(object): def __init__(self): self.a, self.b = 0, 1 #初始化计数器 def __iter__(self): return self #示例本身就是迭代对象，故返回自己 def __next__(self): self.a, self.b = self.b, self.a + self.b if self.a &gt; 1000 : #退出条件 raise StopIteration(): return self.a #返回下一个值 __getitem__123456789&#x27;&#x27;&#x27;__getitem__方法可以实现像list按下标取出元素&#x27;&#x27;&#x27;class Fib(object): def __getitem__(self, n): a, b = 1, 1 for x in range(n): a, b = b, a + b return a __getattr__123456789101112&#x27;&#x27;&#x27;当调用不存在的属性（attribute）或者函数时，Python 解释器会试图调用__getattr__(self, &#x27;score&#x27;)来尝试获得属性，这样，我们就有机会返回 score的值&#x27;&#x27;&#x27;class Student(object): def __init__(self): self.name = &#x27;Kevin&#x27; def __getattr__(self, attr): if attr == &#x27;score&#x27;: return 89 __call__1234567891011&#x27;&#x27;&#x27;任意类,只需定义一个__call__()方法,就可以直接对实例进行调用通过 callable()函数，我们就可以判断一个对象是否是“可调用”对象。&#x27;&#x27;&#x27;class Student(object): def __init__(self, name): self.name = name def __call__(self): print(&#x27;My name is %s.&#x27; % self.name) 枚举类12345678910111213&#x27;&#x27;&#x27;类似C++,Python 提供了 Enum 类来实现这个功能调用 Enum 的第一个参数是枚举的名称。第二个参数是枚举成员名称的来源。&#x27;&#x27;&#x27;from enum import EnumMonth = Enum(&#x27;Month&#x27;, (&#x27;Jan&#x27;, &#x27;Feb&#x27;, &#x27;Mar&#x27;, &#x27;Apr&#x27;, &#x27;May&#x27;, &#x27;Jun&#x27;, &#x27;Jul&#x27;, &#x27;Aug&#x27;, &#x27;Sep&#x27;, &#x27;Oct&#x27;, &#x27;Nov&#x27;, &#x27;Dec&#x27;))for name, member in Month.__members__.items(): print(name, &#x27;=&gt;&#x27;, member, &#x27;,&#x27;, member.value) #value 属性则是自动赋给成员的 int 常量，默认从 1 开始计数 123456789101112131415&#x27;&#x27;&#x27;如果需要更精确地控制枚举类型，可以从 Enum 派生出自定义类&#x27;&#x27;&#x27;from enum import Enum, unique@unique # @unique 装饰器可以检查保证没有重复值class Weekday(Enum): Sun = 0 # Sun 的 value 被设定为 0 Mon = 1 Tue = 2 Wed = 3 Thu = 4 Fri = 5 Sat = 6 访问枚举类型,既可以用成员名称引用枚举常量，又可以直接根据 value 的值获得枚举常量。 使用元类type()class type(object)class type(name, bases, dict) 传入一个参数时，返回 object 的类型。 返回值是一个 type 对象，通常与 object.__class__ 所返回的对象相同。 推荐使用 isinstance() 内置函数来检测对象的类型，因为它会考虑子类的情况。 传入三个参数时，返回一个新的 type 对象。 这在本质上是 class 语句的一种动态形式。 name 字符串即类名并且会成为 __name__ 属性；bases 元组列出基类并且会成为 __bases__ 属性；而 dict 字典为包含类主体定义的命名空间并且会被复制到一个标准字典成为 __dict__ 属性。 例如，下面两条语句会创建相同的 type 对象: 12345&gt;&gt;&gt; class X:... a = 1...&gt;&gt;&gt; X = type(&#x27;X&#x27;, (object,), dict(a=1)) metaclass除了使用 type()动态创建类以外，可以使用 metaclass控制类的行为。 metaclass，直译为元类，简单的解释就是： 当我们定义了类以后，就可以根据这个类创建出实例，所以： 先定义类，然后创建实例。 但是如果我们想创建出类呢？那就必须根据 metaclass 创建出类，所以：先定义 metaclass，然后创建类。 连接起来就是：先定义 metaclass，就可以创建类，最后创建实例。 所以，metaclass 允许你创建类或者修改类。换句话说，你可以把类看成是 metaclass 创建出来的“实例”。 一般来说，应该直接在类的定义中写上方法，但是，有些情况需要通过 metaclass来修改类的定义。例如 ORM——“Object Relational Mapping”，即对象-关系映射，就是把关系数据库的一行映射为一个对象，也就是一个类对应一个表，这样，写代码更简单，不用直接操作 SQL 语句。 错误处理try…except…finally当我们认为某些代码可能会出错时，就可以用 try 来运行这段代码，如果执行出错，则后续代码不会继续执行，而是直接跳转至错误处理代码，即except语句块，执行完except语句块后，若有finally语句，则执行finally语句块。 123456789try: print(&#x27;try...&#x27;) r = 10 / 0 print(&#x27;result:&#x27;, r)except ZeroDivisionError as e: print(&#x27;except:&#x27;, e)finally: print(&#x27;finally...&#x27;) # 至此，执行完毕print(&#x27;End&#x27;) 可使用多个except来捕获多个不同类型的错误，也可以在except语句块后加一个else语句。 12345678910111213try: print(&#x27;try...&#x27;) r = 10 / int(&#x27;2&#x27;) print(&#x27;result:&#x27;, r)except ValueError as e: print(&#x27;ValueError:&#x27;, e)except ZeroDivisionError as e: print(&#x27;ZeroDivisionError:&#x27;, e)else: # 若没有错误发生则执行else语句 print(&#x27;no error!&#x27;)finally: print(&#x27;finally...&#x27;)print(&#x27;End&#x27;) Python的错误也是 class，所有的错误都继承于 BaseException，所以 except不但会捕获该类型错误，还会把其子类也算在其中。比如： 1234567try: foo()except ValueError as e: print(&#x27;ValueError&#x27;)# UnicodeError为ValueError的子类，若出现则已经被上一个except语句捕获except UnicodeError as e: print(&#x27;UnicodeError&#x27;) 使用try…except可以跨越多层调用来捕获错误，所以只需要在合适的层次去捕获错误。 12345678910111213def foo(s): return 10 / int(s)def bar(s): return foo(s) * 2def main(): try: bar(&#x27;0&#x27;) except Exception as e: print(&#x27;Error:&#x27;, e) finally: print(&#x27;finally...&#x27;) 调用堆栈若错误未被捕获，它会一直往上抛，最终被 Python解释器捕获，打印一个错误信息，然后退出。 12345678# err.py:def foo(s): return 10 / int(s)def bar(s): return foo(s) * 2def main(): bar(&#x27;0&#x27;)main() 执行结果如下： Traceback (most recent call last):File “err.py”, line 11, in main()File “err.py”, line 9, in main bar(‘0’) File “err.py”, line 6, in bar return foo(s) * 2 File “err.py”, line 3, in foo return 10 / int(s)ZeroDivisionError: division by zero 记录错误Python内置的 logging模块可以记录错误信息的同时让程序继续执行下去。 1234567891011121314151617# err_logging.pyimport loggingdef foo(s): return 10 /int(s)def bar(s): return foo(s) * 2def main(): try: bar(&#x27;0&#x27;) except Exception as e: logging.exception(e)main()print(&#x27;End&#x27;) 这样虽然也会出错，但程序打印完错误信息后会继续执行，并正常退出。这样做可以方便把错误信息记录到日志文件中，方便日后排查。 $ python3 err_logging.pyERROR:root:division by zeroTraceback (most recent call last): File “err_logging.py”, line 13, in main bar(‘0’) File “err_logging.py”, line 9, in bar return foo(s) * 2 File “err_logging.py”, line 6, in foo return 10 / int(s)ZeroDivisionError: division by zeroEND 抛出错误要知道错误是 class，捕获一个错误即捕获到该 class的一个实例。其不是凭空产生的而是有意创建并抛出的，所以我们可以自己定义一个 class，选择好继承关系，然后用 raise语句抛出一个错误的实例。 1234567891011# err_raise.pyclass FooError(ValueError): passdef foo(s): n = int(s) if n==0: raise FooError(&#x27;invalid value: %s&#x27; % s) return 10 / nfoo(&#x27;0&#x27;) 但是，如无必要，尽量使用内置的错误类型。 还有另一种错误处理方式 123456789101112131415# err_reraise.pydef foo(s): n = int(s) if n == 0: raise ValueError(&#x27;invalid value: %s&#x27; % s) return 10 /ndef bar(): try: foo(&#x27;0&#x27;) except ValueError as e: print(&#x27;ValueError&#x27;) raisebar() 在bar()函数中，虽然已经捕获了错误，但是又把错误通过 raise语句抛出。这种错误处理方式没有问题，而且非常常见。捕获错误仅为记录，便于后续跟踪。因为当前函数不在知道如何处理该错误，所以最恰当的方式就是继续往上抛，让顶层调用者去处理。 raise语句如果不带表达式，raise 会重新引发当前作用域内最后一个激活的异常。 如果当前作用域内没有激活的异常，将会引发 RuntimeError 来提示错误。 此外，在 except中 raise一个 error，还可以把一种类型的错误转化为另一种类型： 1234try: 10 / 0except ZeroDivisionError: raise ValueError(&#x27;input error!&#x27;) 但绝不可以转换毫不相干的两类错误类型。 调试断言（assert）类似于 print()，assert可以在需要查看的地方检查，若断言失败则抛出错误AssertionError。 12345678def foo(s): n = int(s) assert n != 0, &#x27;n is zero!&#x27; # print(&#x27;==&gt; n=%d&#x27; % n) return 10 / ndef main(): foo(&#x27;0&#x27;) 执行结果： Traceback (most recent call last): …AssertionError: n is zero! 程序中如果到处充斥着 assert，和 print()相比也好不到哪去。不过，启动 Python 解释器时可以用 -O 参数来关闭 assert 执行结果： $ python3 -O err.pyTraceback (most recent call last): …ZeroDivisionError: division by zero logginglogging不会抛出错误，允许指定记录信息的级别（debug、info、warning、error等），而且可以同时输出到 console和文件。 1234567import logginglogging.basicConfig(level=logging.INFO)s = &#x27;0&#x27;n = int(s)logging.info(&#x27;n = %d&#x27; % n)print(10 / n) 执行结果： $ python3 err.pyINFO:root:n = 0Traceback (most recent call last):File “err.py”, line 8, in print(10 / n)ZeroDivisionError: division by zero pdb以参数 -m pdb 启动 Python 的调试器 pdb，让程序以单步方式运行，可以随时查看运行状态。 python3 -m pdb err.py pdb.set_trace()在 import pdb后，用 pdb.set_trace()设置断点调试。 IDE上面两种调试方式都可以在IDE中方便的进行。 单元测试单元测试常见于测试驱动开发（TDD：Test-Driven Development），用于对一个模块、一个函数或者一个类来进行正确性检验的测试工作。 一旦编写的一个模块通过了单元测试，若之后发生更改，但其仍能通过单元测试，那么一定程度上它是可用的。 我们来编写一个 Dict 类，这个类的行为和 dict 一致，但是可以通过属性来访问。 12345678910111213141516# mydict.pyclass Dict(dict): def __init__(self, **kw): super().__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r&quot;&#x27;Dict&#x27; object has no attribute &#x27;%s&#x27;&quot; % key) def __setattr__(self, key, value): self[key] = value 然后编写 Dict类的单元测试。 12345678910111213141516171819202122232425262728293031323334353637383940414243# mydict_test.pyimport unittestfrom mydict import Dictclass TestDict(unittest.TestCase): # 测试类从unitttest.TestCase继承 # 只有test开头的方法才是测试方法，对于每类测试都要有一个test_xxx()方法 def test_init(self): d = Dict(a=1, b=&#x27;test&#x27;) # 然后利用断言输出测试是否符合期望 self.assertEqual(d.a, 1) self.assertEqual(d.b, &#x27;test&#x27;) self.assertTrue(isinstance(d, dict)) def test_key(self): d = Dict() d[&#x27;key&#x27;] = &#x27;value&#x27; self.assertEqual(d.key, &#x27;value&#x27;) def test_attr(self): d = Dict() d.key = &#x27;value&#x27; self.assertTrue(&#x27;key&#x27; in d) self.assertEqual(d[&#x27;key&#x27;], &#x27;value&#x27;) def test_keyerror(self): d = Dict() with self.assertRaises(KeyError): value = d[&#x27;empty&#x27;] def test_attrerror(self): d = Dict() with self.assertRaises(AttributeError): value = d.empty&#x27;&#x27;&#x27;利用如下方式运行单元测试，或者使用命令行参数： python3 -m unittest mydict_test&#x27;&#x27;&#x27;if __name__ == &#x27;__main__&#x27;: unittest.main() setUp &amp; tearDown在单元测试中，setUp()和 tearDown()这两个特殊的方法会在调用每一个测试方法前后分别执行。若有必要，可以用来方便的连接和关闭数据库。 1234567class TestDict(unittest.TestCase): def setUp(self): print(&#x27;setUp...&#x27;) def tearDown(self): print(&#x27;tearDown...&#x27;) 文档测试Python 内置的“文档测试”（doctest）模块可以直接提取注释中的代码并执行测试。doctest 严格按照 Python 交互式命令行的输入和输出来判断测试结果是否正确。只有测试异常的时候，可以用…表示中间一大段烦人的输出。 123456789101112131415161718192021222324252627282930313233343536373839404142# mydict.pyclass Dict(dict): &#x27;&#x27;&#x27; Simple dict but also support access as x.y style. &gt;&gt;&gt; d1 = Dict() &gt;&gt;&gt; d1[&#x27;x&#x27;] = 100 &gt;&gt;&gt; d1.x 100 &gt;&gt;&gt; d1.y = 200 &gt;&gt;&gt; d1[&#x27;y&#x27;] 200 &gt;&gt;&gt; d2 = Dict(a=1, b=2, c=&#x27;3&#x27;) &gt;&gt;&gt; d2.c &#x27;3&#x27; &gt;&gt;&gt; d2[&#x27;empty&#x27;] Traceback (most recent call last): ... KeyError: &#x27;empty&#x27; &gt;&gt;&gt; d2.empty Traceback (most recent call last): ... AttributeError: &#x27;Dict&#x27; object has no attribute &#x27;empty&#x27; &#x27;&#x27;&#x27; def __init__(self, **kw): super().__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r&quot;&#x27;Dict&#x27; object has no attribute &#x27;%s&#x27;&quot; % key) def __setattr__(self, key, value): self[key] = valueif __name__ == &#x27;__main__&#x27;: import doctest doctest.testmod() 文件读写读文件要以读文件的模式打开一个文件对象，使用 Python 内置的 open()函数，传入文件名和标示符： 1&gt;&gt;&gt; f = open(&#x27;/Users/michael/test.txt&#x27;, &#x27;r&#x27;) # 标示符&#x27;r&#x27;表示读 如果文件不存在，open()函数就会抛出一个 IOError 的错误，并且给出错误码和详细的信息告诉你文件不存在： 12345&gt;&gt;&gt; f=open(&#x27;/Users/michael/notfound.txt&#x27;, &#x27;r&#x27;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;FileNotFoundError: [Errno 2] No such file or directory: &#x27;/Users/michael/notfound.txt&#x27; 如果打开成功，调用 read()方法可以一次读取文件所有内容。文件使用完后必须调用 close()方法关闭，因为文件对象会占用系统资源，而且在写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。只有调用 close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。 由于文件读写可能出现 IOError，一旦出现就无法调用后面的 close()方法。所以为了无论如何都能正确关闭文件，可以使用下面的方式。 123456789101112# 推荐使用 with语句来自动调用 close()方法,更加简洁with open(&#x27;/path/to/file&#x27;, &#x27;r&#x27;) as f: print(f.read())# 也可以使用 try语句try: f = open(&#x27;/path/to/file&#x27;, &#x27;r&#x27;) print(f.read)finally: if f: f.close() 由于 read()方法一次性会读取文件所有内容，小文件自然没问题，但是为了避免读取较大文件时爆内存，可以反复调用 read(size)方法；也可以调用 readline()每次读取一行内容，方便读取配置文件。 12for line in f.readlines(): print(line.strip()) # 删除末尾&#x27;\\n&#x27; file-like Object类似于 open()函数返回的有 read()方法对象，在 Python中统称为 file-like Object。 除了 file 外，还可以是内存的字节流，网络流，自定义流等等。file-like Object 不要求从特定类继承，只要写个 read()方法就行。StringIO 就是在内存中创建的 file-like Object，常用作临时缓冲。 二进制文件要读取二进制文件，使用 ‘rb’模式打开文件即可 123&gt;&gt;&gt; f = open(&#x27;/Users/michael/test.jpg&#x27;, &#x27;rb&#x27;)&gt;&gt;&gt; f.read()b&#x27;\\xff\\xd8\\xff\\xe1\\x00\\x18Exif\\x00\\x00...&#x27; # 十六进制表示的字节 字符编码在读取文件时，传入 encoding参数来读取不同编码方式的文件。 123&gt;&gt;&gt; f = open(&#x27;gbk.txt&#x27;, &#x27;r&#x27;, encoding=&#x27;gbk&#x27;)&gt;&gt;&gt; f.read()&#x27;测试&#x27; 写文件传入 ‘w’或 ‘wb’来写文本文件或者二进制文件。 123&gt;&gt;&gt; f = open(&#x27;/Users/michael/test.txt&#x27;, &#x27;w&#x27;)&gt;&gt;&gt; f.write(&#x27;Hello, world!&#x27;)&gt;&gt;&gt; f.close() StringIO &amp; BytesIOStringIO使用 StringIO可以在内存中读写 str。 12345678910&gt;&gt;&gt; from io import StringIO&gt;&gt;&gt; f = StringIO()&gt;&gt;&gt; f.write(&#x27; &#x27;)1&gt;&gt;&gt; f.write(&#x27;Hello&#x27;)5&gt;&gt;&gt; f.write(&#x27;Kevin&#x27;)5&gt;&gt;&gt; print(f.getvalue()) # getvalue()用来获取写入后的 str HelloKevin 要读取 StringIO，可以用一个 str 初始化 StringIO，然后，像读文件一样读取： 123456789&gt;&gt;&gt; f = StringIO(&#x27;Hello Kevin!\\nWhat\\&#x27;s up.&#x27;)&gt;&gt;&gt; while True:... s = f.readline()... if s == &#x27;&#x27;:... break... print(s.strip())...Hello Kevin!What&#x27;s up. BytesIO类似于 StringIO，不过是用来读取二进制数据。 123456&gt;&gt;&gt; from io import BytesIO&gt;&gt;&gt; f = BytesIO()&gt;&gt;&gt; f.write(&#x27;中文&#x27;.encode(&#x27;utf-8&#x27;))6&gt;&gt;&gt; print(f.getvalue())b&#x27;\\xe4\\xb8\\xad\\xe6\\x96\\x87&#x27; 123456&gt;&gt;&gt; print(f.getvalue())b&#x27;\\xe4\\xb8\\xad\\xe6\\x96\\x87&#x27;&gt;&gt;&gt; from io import BytesIO&gt;&gt;&gt; f = BytesIO(b&#x27;\\xe4\\xb8\\xad\\xe6\\x96\\x87&#x27;)&gt;&gt;&gt; f.read()b&#x27;\\xe4\\xb8\\xad\\xe6\\x96\\x87&#x27; 操作文件和目录Python 的 os 模块封装了操作系统的目录和文件操作，要注意这些函数有的在 os 模块中，有的在 os.path 模块中。 123&gt;&gt;&gt; import os&gt;&gt;&gt; os.name # 操作系统类型&#x27;nt&#x27; 如果是 posix，说明系统是 Linux、Unix 或 Mac OS X，如果是 nt，就是 Windows系统。 在操作系统中定义的环境变量，全部保存在 os.environ 这个变量中，可以直接查看。要获取某个环境变量的值，可以调用 os.environ.get(‘key’) 方法。 操作文件和目录12345678910# 查看当前目录的绝对路径:&gt;&gt;&gt; os.path.abspath(&#x27;.&#x27;)&#x27;/Users/michael&#x27;# 在某个目录下创建一个新目录，首先把新目录的完整路径表示出来:&gt;&gt;&gt; os.path.join(&#x27;/Users/michael&#x27;, &#x27;testdir&#x27;)&#x27;/Users/michael/testdir&#x27;# 然后创建一个目录:&gt;&gt;&gt; os.mkdir(&#x27;/Users/michael/testdir&#x27;)# 删掉一个目录:&gt;&gt;&gt; os.rmdir(&#x27;/Users/michael/testdir&#x27;) 把两个路径合成一个时，不要直接拼字符串，而要通过 os.path.join() 函数，这样可以正确处理不同操作系统的路径分隔符。 在Linux/Unix/Mac 下，os.path.join() 返回这样的字符串：part-1/part-2而 Windows 下会返回这样的字符串：part-1\\part-2 要拆分路径时，也不要直接去拆字符串，而要通过 os.path.split() 函数，这样可以把一个路径拆分为两部分，后一部分总是最后级别的目录或文件名： 12&gt;&gt;&gt; os.path.split(&#x27;/Users/michael/testdir/file.txt&#x27;)(&#x27;/Users/michael/testdir&#x27;, &#x27;file.txt&#x27;) os.path.splitext()可以直接让你得到文件扩展名，很多时候非常方便： 12&gt;&gt;&gt; os.path.splitext(&#x27;/path/to/file.txt&#x27;)(&#x27;/path/to/file&#x27;, &#x27;.txt&#x27;) 这些合并、拆分路径的函数并不要求目录和文件要真实存在，它们只对字符串进行操作。除了内置的 os 模块，在 shutil 模块中还有很多实用函数，它们可以看做是 os 模块的补充。 利用 Python 特性可以方便的过滤文件： 123456&gt;&gt;&gt; [x for x in os.listdir(&#x27;.&#x27;) if os.path.isdir(x)] # 当前目录下所有目录[&#x27;etc&#x27;]&gt;&gt;&gt; [x for x in os.listdir(&#x27;.&#x27;) if os.path.isfile(x) and os.path.splitext(x)[1]==&#x27;.py&#x27;] # 所有 .py 文件[&#x27;apis.py&#x27;, &#x27;config.py&#x27;, &#x27;models.py&#x27;, &#x27;pymonitor.py&#x27;, &#x27;test_db.py&#x27;, &#x27;urls.py&#x27;, &#x27;wsgiapp.py&#x27;] 序列化pickle在把变量从内存中变成可存储或者传输的过程称之为序列化（pickling），其他语言中也称为 serialization, marshalling, flattening 等。反之，叫做反序列化，即 unpickling。 Python 提供 pickle 模块来实现序列化。 123456789101112&gt;&gt;&gt; import pickle&gt;&gt;&gt; d = dict(name=&#x27;Bob&#x27;, age=20, score=89)&gt;&gt;&gt; pickle.dumps(d) # pickle.dumps()方法把任意对象序列化成一个bytesb&#x27;\\x80\\x04\\x95$\\x00\\x00\\x00\\x00\\x00\\x00\\x00&#125;\\x94(\\x8c\\x04name\\x94\\x8c\\x03Bob\\x94\\x8c\\x03age\\x94K\\x14\\x8c\\x05score\\x94KYu.&#x27;&gt;&gt;&gt; f = open(&#x27;dump.txt&#x27;, &#x27;wb&#x27;)&gt;&gt;&gt; pickle.dump(d, f) # pickle.dump()直接把序列化后的对象写入一个flie-like Object&gt;&gt;&gt; f.close()&gt;&gt;&gt; f = open(&#x27;dump.txt&#x27;, &#x27;rb&#x27;)&gt;&gt;&gt; d = pickle.load(f) # pickle.load()方法从一个 file-like Object 中直接反序列化出对象&gt;&gt;&gt; f.close()&gt;&gt;&gt; d&#123;&#x27;name&#x27;: &#x27;Bob&#x27;, &#x27;age&#x27;: 20, &#x27;score&#x27;: 89&#125; 考虑到兼容性和安全问题， pickle 可以用来保存不重要的数据，但最好不要用来反序列化未知安全性的数据，以防止执行恶意二进制码。 JSON要在不同编程语言之间传递对象，必须把对象序列化为标准格式，如：XML、JSON。考虑到 JSON 更快，而且可以直接在 Web 中直接读取，所以格式化为 JSON 会是一种更好的选择。 JSON 表示的对象就是标准的 JavaScript 语言的对象，JSON 和 Python内置的数据类型对应如下： JSON Pyhton { } dict [ ] list “string” str 123.45 int 或 float true/false Ture/False null None Python 对 JSON 的操作类似于 pickle ，如下： 1234567&gt;&gt;&gt; import json&gt;&gt;&gt; d = dict(name=&#x27;Bob&#x27;, age=20, score=89)&gt;&gt;&gt; json.dumps(d)&#x27;&#123;&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 20, &quot;score&quot;: 89&#125;&#x27;&gt;&gt;&gt; json_str = &#x27;&#123;&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 20, &quot;score&quot;: 89&#125;&#x27;&gt;&gt;&gt; json.loads(json_str)&#123;&#x27;name&#x27;: &#x27;Bob&#x27;, &#x27;age&#x27;: 20, &#x27;score&#x27;: 89&#125; JSON进阶Python 的 dict 对象可以直接序列化为 JSON 的 { }，若要序列化一个 class 则使用可选参数 default 把任意一个对象变成一个可序列化为 JSON 的对象，但需要为 class 专门写一个转换函数，再把函数传进去： 1234567891011121314151617181920import jsonclass Student(object): def __init__(self, name, age, score): self.name = name self.age = age self.score = scoredef student2dict(std): return &#123;&#x27;name&#x27;: std.name, &#x27;age&#x27;: std.age, &#x27;score&#x27;: std.score&#125;s = Student(&#x27;Bob&#x27;, 12, 89)print(json.dumps(s, default=student2dict))# 遇到不同的 class 类，可以取巧使用 __dict__ 属性# 但也有少数例外，比如定义了__slors__的 classprint(json.dumps(s, default=lambda obj: obj.__dict__)) 进程和线程进程由线程组成，操作系统中每一个任务都是一个进程。而操作系统为了实现多任务同时进行需要对进程和线程进行合理调度并在合适的时机杀死进程。实现多任务的方法有以下三种： 多进程模式 多线程模式 多进程+多线程模式 多进程(multiprocessing)Unix/Linux 系统提供一个 fork() 系统调用，其调用一次返回两次，因为操作系统自动把当前进程（父进程）复制一份（子进程），然后分别在父进程和子进程内返回。 Python 中 os.fork() 用来 fork 一个子进程。返回子节点中的 0 以及父节点中的子进程标识。如果发生错误则抛出 OSError。 12345678import osprint(&#x27;Process (%s) start...&#x27; % os.getpid())pid = os.fork()if pid == 0: print(&#x27;child process (%s) ,parent is %s.&#x27; % (os.getpid(), os.getppid()))else: print(&#x27;(%s) just created a child process (%s).&#x27; % (os.getpid(), pid)) 输出如下： Process (9400) start…(9400) just created a child process (9401).child process (9401) ,parent is 9400. 可以看到 if…else 语句确实执行了两次，而且是父进程先返回值。 有了 fork 调用，一个进程在接到新任务时可以复制一个子进程来处理新任务，常见的 Apache 服务器就是由父进程监听端口，每当有新的 http 请求时，就 fork 一个子进程来处理新的 http 请求。 multiprocessingPython 中的 multiprocessing 模块为跨平台版本的多进程模块。它提供一个 Process 类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束。 1234567891011121314151617from multiprocessing import Processimport os# 子进程要执行的代码def run_proc(name): print(&#x27;Run child process %s (%s)...&#x27; % (name, os.getpid()))if __name__ == &#x27;__main__&#x27;: print(&#x27;Parent process %s.&#x27; % os.getpid()) p = Process(target=run_proc, args=(&#x27;test&#x27;, )) print(&#x27;Child process will start.&#x27;) p.start() p.join() print(&#x27;Child process end.&#x27;) 执行结果： Parent process 20204.Child process will start.Run child process test (19332)…Child process end. 创建子进程时， 只需要传入一个执行函数和函数的参数，创建一个 Process 实例，使用 start() 方法启动，使用 join() 方法可以等待子进程结束后再继续往下运行，用于进程间的同步。 Pool若有大量子进程，可以用进程池的方式批量创建： 12345678910111213141516171819202122from multiprocessing import Poolimport os, time, randomdef long_time_task(name): print(&#x27;Run task %s (%s)...&#x27; % (name, os.getpid())) start = time.time() time.sleep(random.random() * 3) end = time.time() print(&#x27;Task %s runs %0.2f seconds.&#x27; % (name, (end - start)))if __name__ == &#x27;__main__&#x27;: print(&#x27;Parent process %s.&#x27; % os.getpid()) p = Pool(4) for i in range(5): p.apply_async(long_time_task, args=(i, )) print(&#x27;Waiting for all subprocesses done...&#x27;) p.close() p.join() print(&#x27;All subprocesses done.&#x27;) 执行结果： Parent process 7524.Waiting for all subprocesses done…Run task 0 (1152)…Run task 1 (10548)…Run task 2 (9068)…Run task 3 (8240)…Task 3 runs 0.54 seconds.Run task 4 (8240)…Task 4 runs 0.08 seconds.Task 1 runs 0.76 seconds.Task 0 runs 2.47 seconds.Task 2 runs 2.75 seconds.All subprocesses done. 对 Pool 对象调用 join() 方法会等待所有子进程执行完毕，调用 join() 方法之前必须先调用 close() 方法， 调用 close() 后就不能继续添加新的 Process。 对输出结果可以注意到，task 0，1，2，3 是立刻执行的，而 task4 需要等待前面某个进程结束后才能执行。因为在我的电脑上只有四颗核心，Pool 有意设计成默认为CPU核心数，若改成：p = Pool(5)就可以同时跑5个进程。 子进程由于子进程不一定是自身，而是一个外部进程。那么，就还需要控制其输入和输出。而使用 subprocess 可以方便的启动一个子进程并控制其输入和输出。 123456import subprocessprint(&#x27;nslookup www.python.org&#x27;)r = subprocess.call([&#x27;nslookup&#x27;, &#x27;www.python.org&#x27;])print(&#x27;exit code:&#x27;, r) 在未连接互联网时的执行结果： nslookup www.python.org服务器: UnKnownAddress: fec0:0:0:ffff::1 *** UnKnown 找不到 www.python.org: No response from serverexit code: 0 如果子进程还需要输入，可通过 communicate() 方法： 1234567891011import subprocessprint(&#x27;$ nslookup&#x27;)p = subprocess.Popen([&#x27;nslookup&#x27;], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)output, err = p.communicate(b&#x27;set q=mx\\npython.org\\nexit\\n&#x27;)print(output.decode(&#x27;utf-8&#x27;)) # 在 Windows 环境下使用 ANSI 格式解码print(&#x27;Exit code:&#x27;, p.returncode) 上面的代码相当于在命令行执行命令 nslookup，然后手动输入： 123set q = mxpython.orgexit 进程间通信为了满足不同进程间互相通信，操作系统提供了很多机制来实现进程间通信。Python 的 multiprocessing 模块包装了底层机制，提供 Queue、Pipes 等多种方式来交换数据。 以 Queue 为例，在父进程中创建两个子进程，一个往 Queue 里写数据，一个从 Queue 里读数据： 1234567891011121314151617181920212223242526272829303132from multiprocessing import Process, Queueimport os, time, random# 写数据进程执行的代码def write(q): print(&#x27;process to write:%s&#x27; % os.getpid()) for value in [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;]: print(&#x27;Put %s to queue.&#x27; % value) q.put(value) time.sleep(random.random())# 读数据进程执行的代码def read(q): print(&#x27;process to read:%s&#x27; % os.getpid()) while True: value = q.get(True) print(&#x27;Get %s from queque.&#x27; % value)if __name__ == &#x27;__main__&#x27;: # 父进程创建 Queue，并传给各子进程 q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程 pw，写入 pw.start() # 启动子进程 pr, 读取 pr.start() # 等待 pw 结束 pw.join() # pr 进程为死循环，只能强行终止 pr.terminate() 执行结果： process to write:17000Put A to queue.process to read:18772Get A from queque.Put B to queue.Get B from queque.Put C to queue.Get C from queque. 在 Unix/Linux 下，multiprocessing 模块封装了 fork() 调用，不需要关心其实现细节。但由于 Window 没有 fork 调用，因此，multiprocessing 需要“模拟”出 fork 的效果，父进程所有 Python 对象都必须通过 pickle 序列化再传到子进程去，所以，如 multiprocessing 在 Windows 下调用失败了，要先考虑是否 pickle 失败。 多线程多任务也可以由进程中多个线程完成。进程是由若干个线程组成的，一个进程至少有一个线程。作为操作系统直接支持的执行单元，线程通常在高级语言中广泛受支持。Python 的线程是真正的 Posix Thread，而不是模拟出来的线程。 Python 的标准库提供两个模块：_thread 和 threading，threading 是封装了_thread的高级模块。大多数情况，我们只需要使用 threading 这个高级模块。 123456789101112131415161718192021import time, threading# 新线程执行的代码def loop(): print(&#x27;thread %s is running...&#x27; % threading.current_thread().name) n = 0 while n &lt; 5: n = n + 1 print(&#x27;thread %s&gt;&gt;&gt;%s&#x27; % (threading.current_thread().name, n)) time.sleep(1) print(&#x27;thread %s ended.&#x27; % threading.current_thread().name)print(&#x27;thread %s is running...&#x27; % threading.current_thread().name)# 把 loop 函数传入并创建 Thread 实例t = threading.Thread(target=loop, name=&#x27;LoopThread&#x27;)t.start() # 调用 start() 开始执行t.join()print(&#x27;thread %s ended.&#x27; % threading.current_thread().name) 执行结果： thread MainThread is running…thread LoopThread is running…thread LoopThread&gt;&gt;&gt;1thread LoopThread&gt;&gt;&gt;2thread LoopThread&gt;&gt;&gt;3thread LoopThread&gt;&gt;&gt;4thread LoopThread&gt;&gt;&gt;5thread LoopThread ended.thread MainThread ended. 任一进程都会创建一个名为 MainThread 的主线程，调用 threading 模块的 current_thread() 函数会返回当前线程的实例。子线程的名字在创建时指定，无特殊意义，用来在打印时显示。 Lock多进程与多线程最大的不同在于，多进程中同一变量在各自进程中都有且互不影响。而在多线程中，所有变量都有所以线程共享，所以任一变量都可以被任一线程修改。这样非常容易出现变量内容不符合预期。看一个例子： 12345678910111213141516171819202122import time, threading# 假设这是你的银行存款balance = 0def change_it(n): # 先取后存，结果应该为0： global balance balance = balance + n balance = balance - ndef run_thread(n): for i in range(100000): change_it(n)t1 = threading.Thread(target = run_thread, args = (5,))t2 = threading.Thread(target = run_thread, args = (8,))t1.start()t2.start()t1.join()t2.join()print(balance) # 多次输出结果不一定为0 为了确保 balance 的值正确，就要给change_it()上一把锁，当某个进程开始执行change_it()时，因为它获得了锁，因此其他线程不能同时执行change_it()，只能等待锁被释放后获得该锁后才能执行change_it()。创建一个锁就是通过threading.Lock()来实现。 123456789101112balance = 0lock = threading.Lock()def run_thread(n): for i in range(100000): # 先要获取锁 lock.acquire() try: change_it(n) finally: # 改完一定要释放锁 lock.release() 为了避免等待锁的线程成为“死线程”，要使用 try…finally 来确保锁一定会被释放。 锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。 多核CPU多核CPU应该同时可以执行多个线程，而一个死循环进程会 100% 占用一个CPU，两个死循环则是 200%的CPU，也就是占用两个核心。要想把 N 核 CPU 的核心全部跑满，就必须启动 N 个死循环线程。 12345678910111213import threading, multiprocessingdef loop(): x = 0 while True: x = x ^ 1for i in range(multiprocessing.cpu_count()): t = threading.Thread(target=loop) t.start() 启动与CPU核心数量相同的 N 个线程，在四核CPU上可以监控到CPU占用率仅有 102%，也就是仅用了一核。 但是用 C、C++或 Java 来改写相同的死循环，直接可以把全部核心跑满，4 核就跑到 400%，8 核就跑到 800%，为什么 Python 不行呢？ 因为 Python 的线程虽然是真正的线程，但解释器执行代码时，有一个GIL 锁：Global Interpreter Lock，任何 Python 线程执行前，必须先获得GIL 锁，然后，每执行 100 条字节码，解释器就自动释放 GIL 锁，让别的线程有机会执行。这个 GIL 全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在 Python 中只能交替执行，即使 100 个线程跑在 100 核 CPU 上，也只能用到 1 个核。 GIL 是 Python 解释器设计的历史遗留问题，通常我们用的解释器是官方实现的 CPython，要真正利用多核，除非重写一个不带 GIL 的解释器。所以，在 Python 中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过 C 扩展来实现，不过这样就失去了 Python 简单易用的特点。 但是，Python 虽然不能利用多线程实现多核任务，却可以通过多进程实现多核任务。多个 Python 进程有各自独立的 GIL 锁，互不影响。 ThreadLocal在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量就必须加锁。 但是局部变量在函数调用的时候，传递起来很麻烦： 12345678910111213141516def process_student(name): std = Student(name) # std 是局部变量，但是每个函数都要使用，因此必须传进去 do_task_1(std) do_task_1(std)def do_task_1(std): do_subtask_1(std) do_subtask_2(std)def do_task_2(std): do_subtask_2(std) do_subtask_2(std) 每个函数一层一层调用这样来传参数明显不行，但是又不能用全局变量，因为每个线程处理不同的 Student 对象，不能共享。 或者可以用一个全局 dict 存放所有的 Student 对象，然后以 thread 自身作为 key 获得线程对应的 Student 对象。 12345678910111213141516171819202122global_dict = &#123;&#125;def std_thread(name): std = Student(name) # 把 std 放到全局变量 global_dict 中： global_dict[threading.current_thread()] = std do_task_1() do_task_2()def do_task_1(): # 不传入 std，而是根据当前线程查找： std = global_dict[threading.current_thread()] ...def do_task_2(): # 任何函数都可以查找当前线程的 std 变量： std = global_dict[threading.current_thread()] ... 这种方式是可行的，就是丑了点，我们还有更简单的方式： 12345678910111213141516171819202122232425import threading# 创建全局 ThreadLocal 对象：local_school = threading.local()def process_student(): # 获取当前线程关联的 student： std = local_school.student print(&#x27;Hello, %s (in %s)&#x27; % (std, threading.current_thread().name))def process_thread(name): # 绑定 ThreadLocal 的 student： local_school.student = name process_student()t1 = threading.Thread(target=process_thread, args=(&#x27;Alice&#x27;, ), name=&#x27;Thread-A&#x27;)t2 = threading.Thread(target=process_thread, args=(&#x27;Bob&#x27;, ), name=&#x27;Thread-B&#x27;)t1.start()t2.start()t1.join()t2.join() 执行结果 Hello, Alice (in Thread-A)Hello, Bob (in Thread-B) 全局变量 local_school 就是一个 ThreadLocal 对象，每个 Thread 对他都可以读写 student 属性，但互不影响。你可以把 local_school 看成全局变量，但每个属性如 local_school.student 都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLOcal会内部处理。 可以理解为全局变量 local_school 是一个 dict，不但可以用 local_school.student，还可以绑定其他变量，如 local_school.teacher 等等。 ThreadLocal 最常用的就是为每一个线程绑定一个数据库连接，HTTP 请求，用户身份信息等，这样一个线程的所有调用的处理函数都可以非常方便的访问这些资源。 进程 vs 线程我们介绍了多进程和多线程，这是实现多任务最常用的两种方式。现在，我们来讨论一 下这两种方式的优缺点。 首先，要实现多任务，通常我们会设计 Master-Worker 模式，Master 负责分配任务，Worker 负责执行任务，因此，多任务环境下，通常是一个 Master，多个 Worker。 如果用多进程实现 Master-Worker，主进程就是 Master，其他进程就是 Worker。 如果用多线程实现 Master-Worker，主线程就是 Master，其他线程就是 Worker。 多进程模式最大的优点就是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他 子进程。（当然主进程挂了所有进程就全挂了，但是 Master 进程只负责分配任务，挂掉的概 率低）著名的 Apache 最早就是采用多进程模式。 多进程模式的缺点是创建进程的代价大，在 Unix/Linux 系统下，用 fork 调用还行，在 Windows 下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和 CPU 的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。 多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是 任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。在 Windows 上，如果一个线程执行的代码出了问题，你经常可以看到这样的提示：“该程序执行了非法操 作，即将关闭”，其实往往是某个线程出了问题，但是操作系统会强制结束整个进程。 在 Windows 下，多线程的效率比多进程要高，所以微软的 IIS 服务器默认采用多线程模 式。由于多线程存在稳定性的问题，IIS 的稳定性就不如 Apache。为了缓解这个问题，IIS 和 Apache 现在又有多进程 + 多线程的混合模式，真是把问题越搞越复杂。 线程切换无论是多进程还是多线程，只要数量一多，效率肯定上不去，为什么呢？ 我们打个比方，假设你不幸正在准备中考，每天晚上需要做语文、数学、英语、物理、化 学这 5 科的作业，每项作业耗时 1 小时。 如果你先花 1 小时做语文作业，做完了，再花 1 小时做数学作业，这样，依次全部做完， 一共花 5 小时，这种方式称为单任务模型，或者批处理任务模型。 假设你打算切换到多任务模型，可以先做 1 分钟语文，再切换到数学作业，做 1 分钟，再切换到英语，以此类推，只要切换速度足够快，这种方式就和单核 CPU 执行多任务是一样的 了，以幼儿园小朋友的眼光来看，你就正在同时写 5 科作业。 但是，切换作业是有代价的，比如从语文切到数学，要先收拾桌子上的语文书本、钢笔 （这叫保存现场），然后，打开数学课本、找出圆规直尺（这叫准备新环境），才能开始做数学作 业。操作系统在切换进程或者线程时也是一样的，它需要先保存当前执行的现场环境（CPU 寄存器状态、内存页等），然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换 内存页等），才能开始执行。这个切换过程虽然很快，但是也需要耗费时间。如果有几千个任 务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情 况最常见的就是硬盘狂响，点窗口无反应，系统处于假死状态。 所以，多任务一旦多到一个限度，就会消耗掉系统所有的资源，结果效率急剧下降，所有任务都做不好。 计算密集型 vs IO 密集型是否采用多任务的第二个考虑是任务的类型。我们可以把任务分为计算密集型和 IO 密 集型。 计算密集型任务的特点是要进行大量的计算，消耗 CPU 资源，比如计算圆周率、对视频进行高清解码等等，全靠 CPU 的运算能力。这种计算密集型任务虽然也可以用多任务完成， 但是任务越多，花在任务切换的时间就越多，CPU 执行任务的效率就越低，所以，要最高效 地利用 CPU，计算密集型任务同时进行的数量应当等于 CPU 的核心数。 计算密集型任务由于主要消耗 CPU 资源，因此，代码运行效率至关重要。Python 这样 的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用 C 语 言编写。 第二种任务的类型是 IO 密集型，涉及到网络、磁盘 IO 的任务都是 IO 密集型任务，这 类任务的特点是 CPU 消耗很少，任务的大部分时间都在等待 IO 操作完成（因为 IO 的速度 远远低于 CPU 和内存的速度）。对于 IO 密集型任务，任务越多，CPU 效率越高，但也有一 个限度。常见的大部分任务都是 IO 密集型任务，比如 Web 应用。 IO 密集型任务执行期间，99% 的时间都花在 IO 上，花在 CPU 上的时间很少，因此，用 运行速度极快的 C 语言替换用 Python 这样运行速度极低的脚本语言，完全无法提升运行效 率。对于 IO 密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言 是首选，C 语言最差。 异步 IO考虑到 CPU 和 IO 之间巨大的速度差异，一个任务在执行的过程中大部分时间都在等待 IO 操作，单进程单线程模型会导致别的任务无法并行执行，因此，我们才需要多进程模型或者多线程模型来支持多任务并发执行。 现代操作系统对 IO 操作已经做了巨大的改进，最大的特点就是支持异步 IO。如果充分利用操作系统提供的异步 IO 支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为事件驱动模型，Nginx 就是支持异步 IO 的 Web 服务器，它在单核 CPU 上采用单进程模型就可以高效地支持多任务。在多核 CPU 上，可以运行多个进程（数量与 CPU 核心数相同），充分利用多核 CPU。由于系统总的进程数量十分有限，因此操作系统调度非常高效。用异步 IO 编程模型来实现多任务是一个主要的趋势。 对应到 Python 语言，单线程的异步编程模型称为协程，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。我们会在后面讨论如何编写协程。 分布式进程Process 比 Thread 更加稳定，而且 Process 可以分布到多台机器上，而 Thread 只能分布到同一机器的多个 CPU 上。 Python 的 multiprocessing 模块不但支持多进程，其中 managers 子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于 managers 模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。 举个例子：如果我们已经有一个通过 Queue 通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？ 原有的 Queue 可以继续使用，但是，通过 managers 模块把 Queue 通过网络暴露出去，就可以让其他机器的进程访问 Queue 了。 我们先看服务进程，服务进程负责启动 Queue，把 Queue 注册到网络上，然后往 Queue 里面写入任务： 1234567891011121314151617181920212223242526272829303132333435363738# task_master.pyimport random, time, queuefrom multiprocessing.managers import BaseManager# 发送任务的队列：task_queue = queue.Queue()# 接受结果的队列result_queue = queue.Queue()# 从 BaseManager 继承的 QueueManager：class QueueManager(BaseManager): pass# 把两个 Queue 都注册到网络上，callable 参数关联了 Queue 对象：QueueManager.register(&#x27;get_task_queue&#x27;, callable=lambda: task_queue)QueueManager.register(&#x27;get_result_queue&#x27;, callable=lambda: result_queue)# 绑定端口 5000，设置验证码&#x27;abc&#x27;：manager = QueueManager(address=(&#x27;&#x27;, 5000), authkey=b&#x27;abc&#x27;)# 启动 Queue：manager.start()# 获得通过网络访问的 Queue 对象：task = manager.get_task_queue()result = manager.get_result_queue()# 放任务：for i in range(10): n = random.randint(0, 10000) print(&#x27;Put task %d...&#x27; % n) task.put(n)print(&#x27;Try get results...&#x27;)for i in range(10): r = result.get(timeout=10) print(&#x27;Result: %s&#x27; % r)# 关闭manager.shutdown()print(&#x27;master exit&#x27;) 请注意，当我们在一台机器上写多进程程序时，创建的 Queue 可以直接拿来用，但是，在分布式多进程环境下，添加任务到 Queue 不可以直接对原始的 task_queue 进行操作，那样就绕过了 QueueManager 的封装，必须通过 manager.get_task_queue() 获得的 Queue接口添加。 然后，在另一台机器启动任务进程： 123456789101112131415161718192021222324252627282930313233343536# task_worker.pyimport time, sys, queuefrom multiprocessing.managers import BaseManager# 创建类似的 QueueManager:class QueueManager(BaseManager): pass# 由于这个 QueueManager 只从网络上获取 Queue，所以注册时只提供名字:QueueManager.register(&#x27;get_task_queue&#x27;)QueueManager.register(&#x27;get_result_queue&#x27;)# 连接到服务器，也就是运行 task_master.py 的机器:server_addr = &#x27;192.168.12.1&#x27;print(&#x27;Connect to server %s...&#x27; % server_addr)# 端口和验证码注意保持与 task_master.py 设置的完全一致:m = QueueManager(address=(server_addr, 5000), authkey=b&#x27;abc&#x27;)# 从网络连接:m.connect()# 获取 Queue 的对象:task = m.get_task_queue()result = m.get_result_queue()# 从 task 队列取任务,并把结果写入 result 队列:for i in range(10): try: n = task.get(timeout=1) print(&#x27;run task %d * %d...&#x27; % (n, n)) r = &#x27;%d * %d = %d&#x27; % (n, n, n * n) time.sleep(1) result.put(r) except Queue.Empty: print(&#x27;task queue is empty.&#x27;)# 处理结束:print(&#x27;worker exit.&#x27;) 这个 Master/Worker 模型虽然简单，但是就是真正的分布式计算，启动多个 worker 就可以把任务分布到几十台机器上，把任务换成发送邮件，就实现了邮件队列的异步发送。 Queue 对象存储在 task_master.py 进程中，而 Queue 之所以能通过网络访问，就是通过 QueueManager 实现的。由于 QueueManager 管理的不止一个 Queue，所以要给每个网络调用的接口起个名字，如 get_task_queue。 authkey 则是为了保证两台机器正常通信，不被恶意干扰。 正则表达式正则表达式是一种用来匹配字符串的强有力武器。其设计思想是用一种描述性的语言来给字符串定义一个规则，凡是符合规则的字符串，就认为它匹配了，否则，该字符串就是不合法的。 判断一个字符串是否为合法的 Email 时，虽然可以编程提取@前后的子串，再分别判断是否为单词和域名，但是这样做不但麻烦，而且代码难以复用。所以使用正则表达式来匹配用户输入是否合法。 基础用法： [0-9a-zA-Z\\_] 可以匹配一个数字、字母或者下划线 [0-9a-zA-Z\\_]+ 可以匹配至少由一个数字、字母或者下划线组成的字符串，比如’a100’，’0_Z’，’Py3000’等等 [a-zA-Z\\_][0-9a-zA-Z_]*可以匹配由字母或下划线开头，后接任意个由一个数字、字母或者下划线组成的字符串，也就是 Python合法的变量 [a-zA-Z_][0-9a-zA-Z\\_]{0, 19}更精确地限制了变量的长度是1-20个字符（前面 1 个字符+后面最多 19 个字符） \\d{3}表示匹配 3 个数字，例如’010’ \\s 可以匹配一个空格（也包括 Tab 等空白符），所以\\s+表示至少有一个空格，例如匹配’ ‘，’ ‘等 \\d{3,8}表示 3-8 个数字，例如’1234567’ A|B 可以匹配 A 或 B，所以[P|p]ython 可以匹配’Python’或者’python’ ^表示行的开头，^\\d 表示必须以数字开头 $表示行的结束，\\d$表示必须以数字结束 py 也可以匹配’python’，但是加上^py$就变成了整行匹配，就只能匹配’py’ 基本符号的总结： 符号 解释 示例 说明 . 匹配任意字符 b.t 可以匹配bat / but / b#t / b1t等 \\w 匹配字母/数字/下划线 b\\wt 可以匹配bat / b1t / b_t等但不能匹配b#t \\s 匹配空白字符（包括\\r、\\n、\\t等） love\\syou 可以匹配love you \\d 匹配数字 \\d\\d 可以匹配01 / 23 / 99等 \\b 匹配单词的边界 \\bThe\\b ^ 匹配字符串的开始 ^The 可以匹配The开头的字符串 $ 匹配字符串的结束 .exe$ 可以匹配.exe结尾的字符串 \\W 匹配非字母/数字/下划线 b\\Wt 可以匹配b#t / b@t等但不能匹配but / b1t / b_t等 \\S 匹配非空白字符 love\\Syou 可以匹配love#you等但不能匹配love you \\D 匹配非数字 \\d\\D 可以匹配9a / 3# / 0F等 \\B 匹配非单词边界 \\Bio\\B [] 匹配来自字符集的任意单一字符 [aeiou] 可以匹配任一元音字母字符 [^] 匹配不在字符集中的任意单一字符 [^aeiou] 可以匹配任一非元音字母字符 * 匹配0次或多次 \\w* + 匹配1次或多次 \\w+ ? 匹配0次或1次 \\w? {N} 匹配N次 \\w{3} {M,} 匹配至少M次 \\w{3,} {M,N} 匹配至少M次至多N次 \\w{3,6} | 分支 foo|bar 可以匹配foo或者bar (?#) 注释 (exp) 匹配exp并捕获到自动命名的组中 (?&lt;name&gt;exp) 匹配exp并捕获到名为name的组中 (?:exp) 匹配exp但是不捕获匹配的文本 (?=exp) 匹配exp前面的位置 \\b\\w+(?=ing) 可以匹配I’m dancing中的danc (?&lt;=exp) 匹配exp后面的位置 (?&lt;=\\bdanc)\\w+\\b 可以匹配I love dancing and reading中的第一个ing (?!exp) 匹配后面不是exp的位置 (?&lt;!exp) 匹配前面不是exp的位置 *? 重复任意次，但尽可能少重复 a.*ba.*?b 将正则表达式应用于aabab，前者会匹配整个字符串aabab，后者会匹配aab和ab两个字符串 +? 重复1次或多次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {M,N}? 重复M到N次，但尽可能少重复 {M,}? 重复M次以上，但尽可能少重复 说明： 如果需要匹配的字符是正则表达式中的特殊字符，那么可以使用\\进行转义处理，例如想匹配小数点可以写成\\.就可以了，因为直接写.会匹配任意字符；同理，想匹配圆括号必须写成\\(和\\)，否则圆括号被视为正则表达式中的分组。 切分字符串用正则表达式切分字符串比用固定的字符更加灵活，例如： 12345678&gt;&gt;&gt; &#x27;a b c&#x27;.split(&#x27; &#x27;) # 正常切分[&#x27;a&#x27;, &#x27;&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]&gt;&gt;&gt; re.split(r&#x27;\\s+&#x27;, &#x27;a b c&#x27;) # 下面使用正则表达式切分[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]&gt;&gt;&gt; re.split(r&#x27;[\\s\\,]+&#x27;, &#x27;a,b, c d&#x27;)[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;]&gt;&gt;&gt; re.split(r&#x27;[\\s\\,\\;]+&#x27;, &#x27;a,b;; c d&#x27;)[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;] 分组除了简单地判断是否匹配之外，正则表达式还有提取字串地功能。用 （）表示的就是要提取的分组（Group）。比如：^(\\d{3})-(\\d{3,8})$ 分别定义了两个组，可以直接从匹配的字符串取出区号和本地号码： 123456789&gt;&gt;&gt; m = re.match(r&#x27;^(\\d&#123;3&#125;)-(\\d&#123;3,8&#125;$)&#x27;, &#x27;010-324555&#x27;)&gt;&gt;&gt; m&lt;re.Match object; span=(0, 10), match=&#x27;010-324555&#x27;&gt;&gt;&gt;&gt; m.group(0)&#x27;010-324555&#x27;&gt;&gt;&gt; m.group(1)&#x27;010&#x27;&gt;&gt;&gt; m.group(2)&#x27;324555&#x27; 如果正则表达式中定义了组，就可以在 Match 对象上用 group() 方法提取出字串。 group(0) 为原始字符串，group(1) 表示第一组子串，之后依次递推。 这个功能非常有用，例如： 1234&gt;&gt;&gt; t = &#x27;19:20:13&#x27;&gt;&gt;&gt; m = re.match(r&#x27;^(0[0-9]|1[0-9]|2[0-3]|[0-9])\\:(0[0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-9]|5[0-9])\\:(0[0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-9]|5[0-9]|[0-9])$&#x27;, t)&gt;&gt;&gt; m.groups()(&#x27;19&#x27;, &#x27;20&#x27;, &#x27;13&#x27;) 贪婪匹配正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。例如： 1234&gt;&gt;&gt; re.match(r&#x27;^(\\d+)(0*)$&#x27;, &#x27;1000980000&#x27;).groups() # 贪婪匹配，无法匹配后面的0(&#x27;1000980000&#x27;, &#x27;&#x27;)&gt;&gt;&gt; re.match(r&#x27;^(\\d+?)(0*)$&#x27;, &#x27;1000980000&#x27;).groups() # 使用 \\d+? 非贪婪匹配(&#x27;100098&#x27;, &#x27;0000&#x27;) 编译由于可以能会经常使用正则表达式，考虑到效率问题可以先编译正则表达式然后用其直接匹配。 123456&gt;&gt;&gt; import re&gt;&gt;&gt; re_telephone = re.compile(r&#x27;^(\\d&#123;3&#125;)-(\\d&#123;3,8&#125;)$&#x27;) # 编译&gt;&gt;&gt; re_telephone.match(&#x27;010-12345&#x27;).groups() # 使用(&#x27;010&#x27;, &#x27;12345&#x27;)&gt;&gt;&gt; re_telephone.match(&#x27;190-90121&#x27;).groups()(&#x27;190&#x27;, &#x27;90121&#x27;) 12re.match(r&#x27;^([0-9a-zA-Z\\_\\.]+)([@])([a-z0-9]+\\.[a-z]&#123;2,3&#125;)$&#x27;, s)re.match(r&#x27;^&lt;([a-zA-Z\\s]+)&gt;\\s([a-zA-Z0-9\\_]+[@][a-z0-9]+\\.[a-z]&#123;2,3&#125;)$&#x27;, s) datetime参考 12345678910111213141516171819202122232425262728293031323334353637from datetime import datetime, timedelta, timezone# 获取当前datetime:now = datetime.now()print(&#x27;now =&#x27;, now)print(&#x27;type(now) =&#x27;, type(now))# 用指定日期时间创建datetime:dt = datetime(2015, 4, 19, 12, 20)print(&#x27;dt =&#x27;, dt)# 把datetime转换为timestamp:print(&#x27;datetime -&gt; timestamp:&#x27;, dt.timestamp())# 把timestamp转换为datetime:t = dt.timestamp()print(&#x27;timestamp -&gt; datetime:&#x27;, datetime.fromtimestamp(t))print(&#x27;timestamp -&gt; datetime as UTC+0:&#x27;, datetime.utcfromtimestamp(t))# 从str读取datetime:cday = datetime.strptime(&#x27;2015-6-1 18:19:59&#x27;, &#x27;%Y-%m-%d %H:%M:%S&#x27;)print(&#x27;strptime:&#x27;, cday)# 把datetime格式化输出:print(&#x27;strftime:&#x27;, cday.strftime(&#x27;%a, %b %d %H:%M&#x27;))# 对日期进行加减:print(&#x27;current datetime =&#x27;, cday)print(&#x27;current + 10 hours =&#x27;, cday + timedelta(hours=10))print(&#x27;current - 1 day =&#x27;, cday - timedelta(days=1))print(&#x27;current + 2.5 days =&#x27;, cday + timedelta(days=2, hours=12))# 把时间从UTC+0时区转换为UTC+8:utc_dt = datetime.utcnow().replace(tzinfo=timezone.utc)utc8_dt = utc_dt.astimezone(timezone(timedelta(hours=8)))print(&#x27;UTC+0:00 now =&#x27;, utc_dt)print(&#x27;UTC+8:00 now =&#x27;, utc8_dt)","categories":[{"name":"Program","slug":"Program","permalink":"http://fwiskevin.github.io/categories/Program/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://fwiskevin.github.io/tags/notes/"}]}],"categories":[{"name":"Program","slug":"Program","permalink":"http://fwiskevin.github.io/categories/Program/"}],"tags":[{"name":"notes","slug":"notes","permalink":"http://fwiskevin.github.io/tags/notes/"}]}